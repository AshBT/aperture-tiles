#!/bin/bash

# Make sure SPARK_HOME is set
if [ "a" == "a""$SPARK_HOME" ]; then
  echo SPARK_HOME not set.  Please set SPARK_HOME environment variable and try again.
  exit 1
fi

# Make sure SCALA_HOME is set
if [ "a" == "a""$SCALA_HOME" ]; then
  echo SCALA_HOME not set.  Please set SCALA_HOME environment variable and try again.
  exit 1
fi


function addJarToSpark {
  scriptGroupId=$1
  scriptArtifactId=$2
  scriptVersion=$3
  qualifier=$4
  echo Group: ${scriptGroupId}
  echo artifact: ${scriptArtifactId}
  echo version: ${scriptVersion}
  echo qualifer: ${qualifier}

  groupDir=`echo ${scriptGroupId} | sed 's|\.|/|g'`
  repo=${HOME}/.m2/repository
  jardir=${repo}/${groupDir}/${scriptArtifactId}/${scriptVersion}
  if [ X${qualifier} = X ]
  then
	  echo No qualifer
	  jar=${jardir}/${scriptArtifactId}-${scriptVersion}.jar
  else
	  echo qualifer
	  jar=${jardir}/${scriptArtifactId}-${scriptVersion}-${qualifier}.jar
  fi


  # Testing for existence of jar
  if [ ! -e ${jar} ]
  then
      echo Error: Looking for ${jar} - not found
      exit
  fi

  # Add the jar to the classpath
  if [ "a" == "a"${ADD_JARS} ]; then
    export ADD_JARS=${jar}
  else
    export ADD_JARS=${ADD_JARS},${jar}
  fi
}






# Set up the spark classpath
# our own jars
addJarToSpark com.oculusinfo math-utilities ${project.version}
addJarToSpark com.oculusinfo binning-utilities ${project.version}
addJarToSpark com.oculusinfo tile-generation ${project.version}
addJarToSpark com.oculusinfo tile-service ${project.version} classes

# framework-related jars
addJarToSpark org.apache.hbase hbase ${hbase-version}
addJarToSpark org.scala-lang scala-library ${scala-version}
#json version is derived indirectly, can't be coded here.
addJarToSpark org.json json 20090211


# export MASTER=local[8]
# export SPARK_MEM=4g

echo Running Spark from $SPARK_HOME
echo Running Spark on $MASTER
echo Running Spark with $SPARK_MEM
echo Running Spark with jars=$ADD_JARS

$SPARK_HOME/bin/spark-shell $*
