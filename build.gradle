import org.apache.tools.ant.filters.ReplaceTokens

// This is the top level build file for the aperture tiles core projects.  Definitions / tasks that
// are shared between sub-projects need to go in here, but care should be taken not to needlessly
// pollute the global namespace.  The 'settings.gradle' file that is also in this directory defines
// the sub-projects that will be built by this file, and 'properies.gradle' contains default property
// values.
apply plugin: "idea"


// Task that reads the "buildType" string property from the command line and writes the the cloudera versions
// versions into the ext namespace (which is where build global vars go).  There is a predefined build
// type in gradle.properties that will be applied if nothing is specified here. 
//
// ********************************************************
// ** ANY NEW DEPLOYMENT VARIANTS NEED TO BE ADDED HERE. **
// ********************************************************
task setBuildVersions {
	switch (buildType) {
		case "cdh5.1.2":
			logger.info "Valid build type found - using $buildType"
			project.ext { // apply project scope to vars, otherwise local to task
				hadoopCommonVersion = "2.3.0-cdh5.1.2"
				hadoopCoreVersion = "2.3.0-mr1-cdh5.1.2"
				hbaseVersion = "0.98.1-cdh5.1.2"
				sparkVersion = "1.0.0-cdh5.1.2"
				dependencyScalaVersion = "2.10"
				scalaVersion = "2.10.3"
			}
		case "cdh5.1.0":
			logger.info "Valid build type found - using $buildType"
			project.ext {
				hadoopCommonVersion = "2.3.0-cdh5.1.0"
				hadoopCoreVersion = "2.3.0-mr1-cdh5.1.0"
				hbaseVersion = "0.98.1-cdh5.1.0"
				sparkVersion = "1.0.0-cdh5.1.0"
				dependencyScalaVersion = "2.10"
				scalaVersion = "2.10.3"
			}
			break
		case "cdh5.0.0":
			logger.info "Valid build type found - using $buildType"
			project.ext {
				hadoopCommonVersion = "2.3.0-cdh5.0.0"
				hadoopCoreVersion = "2.3.0-mr1-cdh5.0.0"
				hbaseVersion = "0.96.1.1-cdh5.0.0"
				sparkVersion = "1.1.1" // Instead of 0.9.0-cdh5.0.0.  We require >= 1.0
				dependencyScalaVersion = "2.10"
				scalaVersion = "2.10.3"
			}
			break
		case "cdh4.6.0":
			logger.info "Valid build type found - using $buildType"
			project.ext {
				hadoopCommonVersion = "2.0.0-cdh4.6.0"
				hadoopCoreVersion = "2.0.0-mr1-cdh4.6.0"
				hbaseVersion = "0.94.15-cdh4.6.0"
				sparkVersion = "1.1.1" // instead of 0.9.0-cdh4.6.0. We require >= 1.0
				dependencyScalaVersion = "2.10"
				scalaVersion = "2.10.3"
			}
			break
		default:
			throw new StopExecutionException("Unsupported build type '$buildType' specified")
	}
}
init.dependsOn setBuildVersions


// Generates files for the gradle wrapper (see http://www.gradle.org/docs/current/userguide/gradle_wrapper.html)
// This only needs to be run when a new version of gradle is used, and the produced files should be checked into
// source control when its done.
task wrapper(type: Wrapper) {
	gradleVersion = '2.1'
}

// Scalac will not allow default output directory for source and build to be the same,
// so point idea at a different location for test output.  This has to be done at every
// level.
allprojects {
	idea {
		module {
			testOutputDir = file('build/test')
		}
	}
}

// General definitions pushed down to all sub-projects - this code is executed within the context
// of each subproject.
subprojects {				

	// Allows for eclipse project files to be generated
	apply plugin: "eclipse"
	// Support for reading from / writing to maven repositories
	apply plugin: "maven"

	// Shared group and version info.  We keep build variant types in the version names so that we get 
	// a set of JARs for each build type written back into the maven repo.
	group = "com.oculusinfo"
	version = "0.4-$buildType-SNAPSHOT"

	// Aperture JS version - shared between a few places
	project.ext.apertureJsVersion = "1.0.9"
	
	// Maven repos to check for artifacts
	repositories {
		mavenLocal()
		mavenCentral()
		maven {
			url = "http://maven.oculus.local:8080/archiva/repository/snapshots/"
		}
		maven {
			url = "http://maven.oculus.local:8080/archiva/repository/internal/"
		}
		maven {			
			url = "https://repository.cloudera.com/artifactory/cloudera-repos"
		}
	}

	// A shared function to determine whether we use the older unified HBase jar, or the
	// newer split jars.  Currently just looks for cdh5 vs other build types.
	ext.checkHBaseSplit = buildType =~ /cdh5\w*/
		
	// A shared function that adds hbase dependencies to the supplied project based on the build type.  
	// We can't use the DSL in this context, so we have to go through the lower level DependencyManager APIs.  
	// The reason this needs special handling is that HBase went from being a single jar in earlier version,
	// to multiple jars in later.  CDH5.x picks up the new split HBase jar, while CDH4.x needs the
	// unified jar.
	ext.addHBaseDependencies = { config ->
		if (config == null || config == "") {
			config = "compile"
		}
		// Anything that starts with cdh5 gets the split HBase jars, others assumed to get old-style unified jar
		if (checkHBaseSplit) {
			logger.info("Matched CDH5x cloudera version - using new-style jars")
			getDependencies().add(config, "org.apache.hbase:hbase-common:$hbaseVersion", {
				exclude group: "asm", module: "asm"
				exclude group: "org.slf4j", module: "slf4j-api"
				exclude group: "org.slf4j", module: "slf4j-log4j12"
			})
			getDependencies().add(config, "org.apache.hbase:hbase-client:$hbaseVersion", {
				exclude group: "asm", module: "asm"
				exclude group: "org.slf4j", module: "slf4j-api"
				exclude group: "org.slf4j", module: "slf4j-log4j12"
			})
			getDependencies().add(config, "org.apache.hbase:hbase-server:$hbaseVersion", {
				exclude group: "asm", module: "asm"
				exclude group: "org.slf4j", module: "slf4j-api"
				exclude group: "org.slf4j", module: "slf4j-log4j12"
				exclude group: "org.mortbay.jetty", module: "servlet-api-2.5"
			})
		} else {
			logger.info("Did not match CDH5x cloudera version - using old style monolithic jar")
			getDependencies().add(config, "org.apache.hbase:hbase:$hbaseVersion", {
				exclude group: "asm", module: "asm"
				exclude group: "org.slf4j", module: "slf4j-api"
				exclude group: "org.slf4j", module: "slf4j-log4j12"
				exclude group: "org.mortbay.jetty", module: "servlet-api-2.5"
			})
		}
	}	
	
	// Function passed down to subprojects that produces calls to add hbase jars
	// to a spark-run script.
	ext.getHBaseJarStrings = {
		if (checkHBaseSplit) {
			"""\
addSparkJar org.apache.hbase hbase-common $hbaseVersion
addSparkJar org.apache.hbase hbase-server $hbaseVersion
addSparkJar org.apache.hbase hbase-client $hbaseVersion"""
		} else {
			"addSparkJar org.apache.hbase hbase $hbaseVersion"
		}		
	}
	
	// Function passed down to subprojects that poduces hbase class path entries
	// to be used in run scripts. 
	ext.getHBaseClasspathEntries = {
		if (checkHBaseSplit) {
			"\${LIB}/hbase-client.jar:\${LIB}/hbase-server.jar:\${LIB}/hbase-common.jar"
		} else {
			"\${LIB}/hbase.jar"
		}
	}
	
	// Once evaluation is done (each build file has been loaded and processed, but
	// the build hasn't started) add behavior specific to web client projects.
	// Client projects are flagged by a property called 'clientProject' - if that's present,
	// the client behavior gets injected into the project in question.
	afterEvaluate { Project proj ->
		if (proj.ext.has("clientProject") && project.clientProject) {
			
			// Configure the jetty run task
			jettyRun {
				httpPort = 8080
				contextPath = project.name
			}

			// Add the tile service project output
			dependencies {
				compile project(path: ":tile-service")
				compile project(path: ":annotation-service")
			}

			// configure the war task to pick up the tile client files
			war {
				from project(":tile-client").configurations.clientFiles.artifacts.files
			}

			war.dependsOn ":tile-client:exportClientFiles"
		}
	}
}
