# spark connection details - specify the url of your spark master, connection
# user and location of spark home directory
spark.connection.url=spark://hadoop-s1.oculus.local:7077
spark.connection.home=/opt/spark
# used to help distingish spark jobs in the spark or mesos UI, so other users
# can see who is running the job
spark.connection.user=mkielo

# output files to the current directory of the filesystem, and give them a
# prefix, to distinguish them from other runs
oculus.tileio.type=file
oculus.binning.prefix=test

oculus.binning.output.location=output/fpSamp.txt


# Name of the binning dataset
oculus.binning.name=rdns
# location of raw input data - this can be a single file, or a directory full
# of files (which is standard for Spark).  If a directory, all files in the
# directory will be read.
oculus.binning.source.location=hdfs://hadoop-s1:8020//user/mkielo/net-scan/fingerprints/fingerPrintsCandidateSample1000.csv
#character used as a field delimiter
oculus.binning.parsing.separator=\t

# Define which tests to run on the entire table
oculus.binning.table.tests=

# Define the fields to parse in the CSV files
oculus.binning.parsing.fp.index=2
oculus.binning.parsing.fp.fieldType=string
oculus.binning.parsing.fp.tests=none
oculus.binning.parsing.fp.custom.analytics=fingerprints
oculus.binning.parsing.fp.custom.variables=
oculus.binning.parsing.fp.custom.output=output/customAnalytic/FP.txt
