# spark connection details - specify the url of your spark master, connection
# user and location of spark home directory
spark.connection.url=local
spark.connection.home=/opt/spark-0.7.2
# used to help distingish spark jobs in the spark or mesos UI, so other users
# can see who is running the job
spark.connection.user=ndk

# output files to the current directory of the filesystem, and give them a
# prefix, to distinguish them from other runs
oculus.tileio.type=file
oculus.binning.prefix=test

oculus.binning.output.location=c:\\Users\\mkielo\\workspace\\output\\julia-test2.txt


# Name of the binning dataset
oculus.binning.name=rdns
# location of raw input data - this can be a single file, or a directory full
# of files (which is standard for Spark).  If a directory, all files in the
# directory will be read.
oculus.binning.source.location=hdfs://hadoop-s1:8020/xdata/data/julia/5000by200
#character used as a field delimiter
oculus.binning.parsing.separator=\t

# Define which tests to run on the entire table
oculus.binning.table.tests=

# Define the fields to parse in the CSV files
oculus.binning.parsing.x.index=0
oculus.binning.parsing.x.fieldType=double
oculus.binning.parsing.x.tests=max
oculus.binning.parsing.x.customAnalytics=

# val tf = sc.TextFile("hdfs://hadoop-s1:8020/xdata/data/julia/5000by200")