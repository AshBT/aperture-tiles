<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<title>Documentation | Aperture Tiles</title>
<link rel="stylesheet" type="text/css" href="../../css/all.css">
<link rel="stylesheet" type="text/css" href="../../jstests/test.css">
<link rel="stylesheet" href="../../prettify/default.css">
<link rel="SHORTCUT ICON" href="../../img/aperture-16x16.ico" />
<script src="../../lib/jquery.js"></script>
<script src="../../lib/ga.js"></script>
</head>

<body>
	<div id="header"></div>
	<div id="content-strip">
		<div id="header-logo">
			<a href="../../"><img src="../../img/aperture-tiles-big.png"></a>
		</div>
		<div id="header-menu">
			<a href="../../" class="overview">&nbsp;</a> 
			<a href="../../tour/overview/">Tour</a> 
			<a href="../../documentation/setup/" class="selected">Documentation</a>
			<a href="../../demos/">Demos</a> 
			<a href="https://github.com/oculusinfo/aperture-tiles" target="_blank">Download</a>
		</div>

		<div id="all">
			<div id="submenu">
				<div class="submenu-item"
					onclick="window.location.assign('../setup/');">
					<div class="submenu-item-background">
						<div class="submenu-item-number">1</div>
					</div>
					<div class="submenu-item-label">Installation</div>
				</div>
				<div class="submenu-item" onclick="window.location.assign('');">
					<div class="submenu-item-background selected">
						<div class="submenu-item-number">2</div>
					</div>
					<div class="submenu-item-label">Generation</div>
				</div>
				<div class="submenu-item"
					onclick="window.location.assign('../configuration/');">
					<div class="submenu-item-background">
						<div class="submenu-item-number">3</div>
					</div>
					<div class="submenu-item-label">Configure</div>
				</div>
			</div>

			<div id="content">
				<div class="content-context">
					<ul class="toc right">
						<li><a href="#requirements">Requirements</a></li>
						<li><a href="#sysconfig">System Configuration</a></li>
						<li><a href="#running">Running a Tile Job</a>
							<ul>
								<li><a href="#tabdata">Tabular Data</a></li>
								<li><a href="#base">Base Files</a></li>
								<li><a href="#properties">Properties File</a></li>
								<li><a href="#examples">Examples</a></li>
							</ul>
						</li>
						</ul>
				</div>

				<div class="content-body">
					<h1>Tile Generation</h1>
					<p>
						Aperture Tiles provides a framework for computing tile-based analytics using the 
						Apache Spark engine for large-scale data processing.  Built-in support is provided
						for computing aggregation of numeric data using: summation, min and max ranges, time series,
						and top keywords.  Aperture Tiles provides support for custom tile-based analytics 
						through our <em>RDDBinner</em> and <em>ObjectifiedBinner</em> API. Compatible tile sets 
						can also be created using any tool provided they adhere to our AVRO schema (documentation coming soon). 
					</p>
					
					<a name="requirements"></a>
					<h2>Requirements</h2>
					<p>
						Spark version 0.7.2 or greater (version 0.8.1 recommended); Scala version 2.9.3 <br/>
						Optional: HBASE; Hadoop (multiple possible versions) 
					</p>
						
					<a name="sysconfig"></a>
					<h2>System Configuration</h2>
					
					<p>
						Spark determines which version of Hadoop to use by
						looking in <em>$SPARK_HOME/project/<strong>SparkBuild.scala</strong></em>. Instructions for
						what to change are contained therein.
					</p>
					
					<p>
						If you are building your own tiles, a spark-run script is included
						that simplifies running spark jobs, making sure all the
						necessary libraries are included and setting various parameters. 
						The script is located at <em>aperture-tiles/tile-generation/scripts/<strong>spark-run</strong></em>.
						To use this script you must set the following environment variables:
					</p>
					
					<pre class="code">SCALA_HOME - the path to the scala installation directory
SPARK_HOME - the path to the spark installation directory</pre>
				
					<p>
						The <strong>spark-run</strong> script looks for required .jar files it needs in the local Maven
						repository - in order to use it, you first must run 'mvn
						install' in the root of the aperture-tiles project as outlined in the 
						<a href="../setup">Installation documentation</a>. 
					</p>
					
					<p>
						If you plan to store generated tiles in HBase, you will need to edit the
						version number of HBase in spark-run to the correct version. Find the line
						after "# framework-related jars" and edit the version accordingly.  For 
						example if the version of HBase is cloudera 4.4.0 edit the line as: 
					</p>
					
					<pre class="code"># framework-related jars
addToSparkClasspath org.apache.hbase hbase 0.94.6-cdh4.4.0</pre>
					
					<a name="running"></a>
					<h2>Running a Tiling Job</h2>
					
					<a name="tabdata"></a>
					<h3>Tabular Data</h3>
					<p>
						If your data is in numeric and in tabular form -
						character-separated files (CSV, or Comma-separated-values, for
						instance) - the simplest way to process your data is to use the
						CSVBinner tool. If your data is in other formats or you wish to aggregate
						your data using analytics not provided by Aperture Tiles see the 
						tile examples source code. 
					</p>
					
					<p>
						To use the CSVBinner, create a set of properties files
						describing the binning job. The first such properties file is a
						base file, describing the general characteristics of the data. The
						second describes the specific attributes you want tiled, and the
						levels of tiling required. Both use the standard Java property
						file format, which means they can include comments (lines
						beginning with '#' are considered comments).
					</p>
					
					<p>
						The output of the binning process will be a collection of
						AVRO tile data files in the specified location (hbase or local
						filesystem).
					</p>
					
					<p>
						To execute the tiling job using the spark-run script passing
						in the base and tiling property files, use a command similar
						to:
					</p>
					
					<pre class="code">spark-run com.oculusinfo.tilegen.examples.apps.CSVBinner -d /data/twitter/dataset-base.bd /data/twitter/dataset.lon.lat.bd</pre>
					
					<p>
						Where the -d switch specifies the base file path and property
						file. 
					</p>
						
					<a name="base"></a>
					<h3>Base Files</h3>
					<p>
						The following properties must be defined in the base property file:
					</p>
					
					<pre class="code">spark.connection.url
   The location of the spark master.  Use "local" for spark standalone.
   Defaults to "spark://localhost:7077"

spark.connection.home
   The file system location of Spark in the remote location 
   (and, necessarily, on the local machine too)
   Defaults to "/opt/spark-0.7.2"

spark.connection.user
   A user name to stick in the job title so people know who is running the job

oculus.tileio.type
   The way in which tiles are written - either hbase (to write to hbase, 
   see hbase properties below to specify hbase configuration) or
   file to write to the local file system
   Default is file</pre>
        
					<p>
						If <strong>oculus.tileio.type</strong> is set to "hbase" specify the hbase connection configuration properties:
					</p>
					
					<pre class="code">hbase.zookeeper.quorum
   If tiles are written to hbase, the zookeeper quorum location needed 
   to connect to hbase.

hbase.zookeeper.port
   If tiles are written to hbase, the port through which to connect 
   to zookeeper

hbase.master
   If tiles are written to hbase, the location of the hbase master to 
   which to write them</pre>
        
					<p>
						The rest of the configuration properties describe the dataset to be tiled.
					</p>
					
					<pre class="code">oculus.binning.source.location
   The path to the data file or files to be binned

oculus.binning.prefix
   A prefix to be prepended to the name of every pyramid location, used to 
   separate this run of binning from previous runs. 
   If not present, no prefix is used.

oculus.binning.parsing.separator
   The character or string to use as a separator between columns in input
   data files. Default is a tab.

oculus.binning.parsing.&lt;field&gt;.index
   The column number of the described field in the input data files
   This field is mandatory for every field type to be used

oculus.binning.parsing.&lt;field&gt;.fieldType
   The type of value expected in the column specified by 
   oculus.binning.parsing.&lt;field&gt;.index.
   Default is to treat the column as containing real, double-precision values.
   Other possible types are:
       constant or zero - treat the column as containing 0.0 
                          (the column doesn't actually have to exist)
       int - treat the column as containing integers
       long - treat the column as containing double-precision integers
       date - treat the column as containing a date.  The date will be parsed
              and transformed into milliseconds since the standard
              Java start date (using SimpleDateFormatter).
              Default format is yyMMddHHmm, but this can be overridden using
              the oculus.binning.parsing.&lt;field&gt;.dateFormat
       propertyMap - treat the column as a property map.  Further information
                     is then needed to get the specific property.  All four
                     of the following properties must be present to 
                     read the property.
          oculus.binning.parsing.&lt;field&gt;.property 
             name of the property to read
          oculus.binning.parsing.&lt;field&gt;.propertyType
             equivalent to fieldType
          oculus.binning.parsing.&lt;field&gt;.propertySeparator
             character or string to use to separate one property from the next
          oculus.binning.parsing.&lt;field&gt;.propertyValueSeparator
             character or string used to separate a property key from its value

oculus.binning.parsing.&lt;field&gt;.fieldScaling
   How the field values should be scaled. Default is to leave values as they are.
   Other possibilities are:
       log - take the log of the value (oculus.binning.parsing.&lt;field&gt;.fieldBase
             is used, just as with fieldAggregation)

oculus.binning.parsing.&lt;field&gt;.fieldAggregation
   The method of aggregation to be used on values of the X field.
   Default is addition.  Other possible aggregation types are:
       min - find the minimum value
       max - find the maximum value
       log - treat the number as a  logarithmic value; aggregation of a and b is 
             log_base(base^a+base^b).  Base is taken from property
             oculus.binning.parsing.&lt;field&gt;.fieldBase, and defaults to e</pre>
					
					<a name="properties"></a>
					<h3>Properties File</h3>
					<p>
						The properties file defines the tiling job parameters, which fields to bin on and how values are binned.
					</p>
					
					<pre class="code">oculus.binning.name
   The name of the output data tile pyramid

oculus.binning.projection
   The type of projection to use when binning data.  Possible values are:
       EPSG:4326 - bin linearly over the whole range of values found (default)
       EPSG:900913 - web-mercator projection (used for geographic values only)

oculus.binning.xField
   The field to use as the X axis value

oculus.binning.yField
   The field to use as the Y axis value.  
   Defaults to none (i.e., a density strip of x data)

oculus.binning.valueField
   The field to use as the bin value
   Default is to count entries only

oculus.binning.levels.&lt;order&gt;
   This is an array property - i.e., if one wants to bin levels in three groups, 
   then one should have oculus.binning.levels.0, oculus.binning.levels.1, and 
   oculus.binning.levels.2.  Each is a description of the levels to bin in that 
   group - a comma-separate list of individual integers, or ranges of integers 
   (described as start-end).  So "0-3,5" would mean levels 0, 1, 2, 3, and 5.
   If there are multiple level sets, the parsing of the raw data is only done 
   once, and is cached for use with each level set.
   This property is mandatory, and has no default.

oculus.binning.consolidationPartitions
   The number of partitions into which to consolidate data when binning it. 
   If left out, spark will automatically select the number of partitions.</pre>
        
					<a name="examples"></a>
					<h3>Examples</h3>
					<p>
						We include a few example configuration files in <em>aperture-tiles/tile-generation/data</em> directory.
					</p>
					
					<p>
						<strong>twitter-local-base.bd</strong> is an example base property file for a
						locally stored dataset of ID, TIME, LATITUDE, LONGITUDE, with the
						tiles also output to the local file system.
					</p>
					<p>
						<strong>twitter-hdfs-base.bd</strong> is an example base property file for
						the same dataset, but stored in hdfs, and output to hbase.
					</p>
					<p>
						<strong>twitter-lon-lat.bd</strong> is an example tiling file that takes
						either of the base files above, and tells the system to tile
						levels 0-9 of the longitude and latitude data contained therein.
					</p>
				</div>
			</div>
		</div>
	</div>
</body>


</html>
